{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using Gurobi\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Graphs\n",
    "using MetaGraphsNext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General structure:\n",
    "\n",
    "Use a dictionary to store all parameters\n",
    "\n",
    "Use a directed graph to represent the order of preference\n",
    "\n",
    "We can use an extra slack to activate\n",
    "\n",
    "Make sure the problem with all constraints is infeasible\n",
    "\n",
    "Three methods to obtain a solution:\n",
    "\n",
    "1. Give weights to constraints (slack variables controlling how much we violate each) in the objective.\n",
    "We can have a method that takes in the parameter dictionary, and returns a problem.\n",
    "\n",
    "2. Iterate over all possible combinations of constraints, find the best set of constraints.\n",
    "It's probably the most complicated part...\n",
    "\n",
    "3. Use integer optimization to find the best set of constraints to satisfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a dictionary to store all the data\n",
    "data = Dict()\n",
    "\n",
    "# Data example, as a portfolio optimization problem with 5 assets. Actual data should come from the OR database\n",
    "data[\"mean_return\"] = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "data[\"standard_deviation\"] = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "data[\"covariance_matrix\"] = [1.0 0.1 0.2 0.3 0.4;\n",
    "                             0.1 1.0 0.1 0.2 0.3;\n",
    "                             0.2 0.1 1.0 0.1 0.2;\n",
    "                             0.3 0.2 0.1 1.0 0.1;\n",
    "                             0.4 0.3 0.2 0.1 1.0]\n",
    "# Data example, we have extra parameters for constraints\n",
    "data[\"expected_return\"] = 0.2\n",
    "data[\"maximum_uncertainty\"] = 0.1\n",
    "data[\"max_invest_in_each_asset\"] = 0.5\n",
    "# Basic parameters taken from the data\n",
    "data[\"n_assets\"] = length(data[\"mean_return\"])\n",
    "\n",
    "# Let's use a dictionary to store all constraints\n",
    "constraints = Dict()\n",
    "# For each constraint, we need to define weight and functions to add and remove the constraint\n",
    "# It's a lot of work, but I didn't find a better way to do it\n",
    "constraints[\"expected_return\"] = Dict(\n",
    "    \"weight\" => 0.1, # weight for the objective function, only used in the minimize weighted violation method\n",
    "\n",
    "    # this function takes an optimization model and the data, and returns the model with the plain constraint added\n",
    "    #Note that the model must have proper variables defined, otherwise this function will fail\n",
    "    \"add_plain_constraint\" => function(model, data)\n",
    "        @constraint(model, expected_return,\n",
    "                    sum(invest_portion[i]*data[\"mean_return\"][i] for i in 1:data[\"n_assets\"]) >= data[\"expected_return\"],\n",
    "                    base_name=\"expected_return\",\n",
    "                    )\n",
    "        return model\n",
    "    end,\n",
    "    # this function rmoves the constraint from the model. useful for the graph search algorithm\n",
    "    \"remove_plain_constraint\" => function(model, data)\n",
    "        try\n",
    "            delete(model, expected_return)\n",
    "            deregister(model, expected_return)\n",
    "        catch e\n",
    "            println(\"Constraint expected_return not found\")\n",
    "        end\n",
    "        return model\n",
    "    end,\n",
    "\n",
    "    # this function takes an optimization model and the data, and returns the model with the constraint added\n",
    "    #Here we also require the violation slack variable, `violation`, is alreay defined in the model\n",
    "    \"add_constraint_with_violation\" => function(model, data)\n",
    "        @constraint(model,\n",
    "                    sum(invest_portion[i]*data[\"mean_return\"][i] for i in 1:data[\"n_assets\"]) >= data[\"expected_return\"] - violation[\"expected_return\"],\n",
    "                    base_name=\"expected_return\"),\n",
    "        return model\n",
    "    end,\n",
    "\n",
    "    # this function takes an optimization model and the data, and returns the model with the constraint added\n",
    "    #Here we require the binary variable, `satisfied`, indicating if the constraint is required to be satisfied (1) or not (0) is already defined in the model\n",
    "    \"add_constraint_with_binary\" => function(model, data)\n",
    "        expected_return_binary = @variable(model, base_name=\"expected_return_binary\")\n",
    "        large_constant = 10 * maximum(data[\"mean_return\"]) # a large constant for this constraint\n",
    "        @constraint(model,\n",
    "                    sum(invest_portion[i]*data[\"mean_return\"][i] for i in 1:data[\"n_assets\"]) >= data[\"expected_return\"] - (1-satisfied[\"expected_return\"])*large_constant,\n",
    "                    base_name=\"expected_return\",\n",
    "                    )\n",
    "        return model\n",
    "    end,\n",
    ")\n",
    "# another constraint, the variance\n",
    "constraints[\"variance_in_return\"] = Dict(\n",
    "    \"weight\" => 0.2,\n",
    "\n",
    "    \"add_plain_constraint\" => function(model, data)\n",
    "        @constraint(model, variance_in_return,\n",
    "                    sum(invest_portion[i]*invest_portion[j]*data[\"standard_deviation\"][i]*data[\"standard_deviation\"][i]*data[\"covariance_matrix\"][i,j] for i in 1:data[\"n_assets\"], j in 1:data[\"n_assets\"]) <= data[\"maximum_uncertainty\"]^2,\n",
    "                    base_name=\"variance_in_return\",\n",
    "                    )\n",
    "        return model\n",
    "    end,\n",
    "    \"remove_plain_constraint\" => function(model, data)\n",
    "        try\n",
    "            delete(model, variance_in_return)\n",
    "            deregister(model, variance_in_return)\n",
    "        catch e\n",
    "            println(\"Constraint variance_in_return not found\")\n",
    "        end\n",
    "        return model\n",
    "    end,\n",
    "\n",
    "    \"add_constraint_with_violation\" => function(model, data)\n",
    "        @constraint(model,\n",
    "                    sum(invest_portion[i]*invest_portion[j]*data[\"standard_deviation\"][i]*data[\"standard_deviation\"][i]*data[\"covariance_matrix\"][i,j] for i in 1:data[\"n_assets\"], j in 1:data[\"n_assets\"]) <= data[\"maximum_uncertainty\"]^2 + violation[\"variance_in_return\"],\n",
    "                    base_name=\"variance_in_return\",\n",
    "                    )\n",
    "        return model\n",
    "    end,\n",
    "\n",
    "    \"add_constraint_with_binary\" => function(model, data)\n",
    "        variance_in_return_binary = @variable(model, base_name=\"variance_in_return_binary\")\n",
    "        large_constant = 10 * maximum(data[\"standard_deviation\"])^2 # a large constant for this constraint\n",
    "        @constraint(model,\n",
    "                    sum(invest_portion[i]*invest_portion[j]*data[\"standard_deviation\"][i]*data[\"standard_deviation\"][j]*data[\"covariance_matrix\"][i,j] for i in 1:data[\"n_assets\"], j in 1:data[\"n_assets\"]) <= data[\"maximum_uncertainty\"]^2 + (1-satisfied[\"variance_in_return\"])*large_constant,\n",
    "                    base_name=\"variance_in_return\",\n",
    "                    )\n",
    "        return model\n",
    "    end,\n",
    ")\n",
    "\n",
    "    \n",
    "\n",
    "# Let's use a list to encode the preferences\n",
    "preferenece = [\n",
    "    (\"expected_return\", \"variance_in_return\"), # this line means the constraint is more important than variance_in_return\n",
    "    (\"expected_return\", \"max_invest_in_each_asset\"), # this line means the constraint is more important than max_invest_in_each_asset\n",
    "    (\"max_invest_in_each_asset\", \"variance_in_return\"), # this line means the constraint is more important than variance_in_retur.\n",
    "    # more lines can be added here\n",
    "]\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use Julia's Graphs package to represent the preferences as a graph\n",
    "# Data on the vertices will be the (name, distance to dymmy vertex) tuple\n",
    "priority_graph = MetaGraph(DiGraph(); label_type=Symbol, vertex_data_type=Tuple{String, Int64}, edge_data_type=String)\n",
    "\n",
    "add_vertex!(priority_graph, :Dummy, (\"Dummy\", 0))\n",
    "for (name, _) in constraints\n",
    "    add_vertex!(priority_graph, Symbol(name), (name, 1))\n",
    "end\n",
    "\n",
    "add_vertex!(priority_graph, :max_invest_in_each_asset, (\"max_invest_in_each_asset\", 1)) # Not in the constraints dictionary yet\n",
    "\n",
    "for (v1, v2) in preferenece\n",
    "    add_edge!(priority_graph, Symbol(v1), Symbol(v2), \"preference\")\n",
    "end\n",
    "\n",
    "# calculate the transitive reduction of the graph\n",
    "priority_graph = transitivereduction(priority_graph)\n",
    "\n",
    "collect(edges(priority_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parts are free test fields.\n",
    "Not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_test = \"expected_return\"\n",
    "typeof(string_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the slack varaible method\n",
    "\n",
    "test_problem = Model(Gurobi.Optimizer)\n",
    "\n",
    "test_dic = Dict(\n",
    "    \"a\" => 1,\n",
    "    \"b\" => 2,\n",
    ")\n",
    "\n",
    "@variable(test_problem, x[1:10] >= 0)\n",
    "@variable(test_problem, slack_for_active[1:10])\n",
    "@variable(test_problem, dummy[keys(test_dic)] >= 0)\n",
    "\n",
    "@objective(test_problem, Max, sum(x[i] for i in 1:10))\n",
    "\n",
    "@constraint(test_problem, [i=1:10], x[i] <= 10 + slack_for_active[i], base_name=\"maybe_active\")\n",
    "@constraint(test_problem, sum(x[i] for i in 1:10) <= 20, base_name=\"total\")\n",
    "\n",
    "optimize!(test_problem)\n",
    "test_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:10\n",
    "    fix(slack_for_active[i], 0)\n",
    "end\n",
    "\n",
    "optimize!(test_problem)\n",
    "test_problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(is_valid(test_problem, constraint_by_name(test_problem, \"maybe_active[1]\")))\n",
    "cons = constraint_by_name(test_problem, \"maybe_active[1]\")\n",
    "delete(test_problem, cons)\n",
    "unregister(test_problem, :cons)\n",
    "println(is_valid(test_problem, cons))\n",
    "\n",
    "cons = constraint_by_name(test_problem, \"total\")\n",
    "println(is_valid(test_problem, cons))\n",
    "delete(test_problem, cons)\n",
    "unregister(test_problem, :cons)\n",
    "println(is_valid(test_problem, cons))\n",
    "\n",
    "optimize!(test_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(test_problem, x[1] <= 10 + slack_for_active[1], base_name=\"maybe_active[1]\")\n",
    "\n",
    "optimize!(test_problem)\n",
    "\n",
    "test_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize!(test_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1:10\n",
    "    unfix(slack_for_active[i])\n",
    "end\n",
    "\n",
    "optimize!(test_problem)\n",
    "test_problem\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
